{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: an introduction\n",
    "\n",
    "Following: http://www.folgertkarsdorp.nl/word2vec-an-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec (Mikolov et al, 2013) is a tool for learning continuous word embeddings from raw text. It associates words with points in space, and the spatial distance between words describes the similarity between them. Words are represented by continuous vectors over `x` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perdue/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAECCAYAAAD0JMwBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11841e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['queen', 'book', 'king', 'magazine', 'car', 'bike']\n",
    "vectors = np.array([[0.1, 0.3],\n",
    "                   [-0.5, -0.1],\n",
    "                   [0.2, 0.2],\n",
    "                   [-0.3, -0.2],\n",
    "                   [-0.5, 0.4],\n",
    "                   [-0.45, 0.3]])\n",
    "sb.plt.plot(vectors[:,0], vectors[:,1], 'o')\n",
    "sb.plt.xlim(-0.6, 0.3)\n",
    "sb.plt.ylim(-0.3, 0.5)\n",
    "for word, x, y in zip(words, vectors[:,0], vectors[:,1]):\n",
    "    sb.plt.annotate(word, (x, y), size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The displacement vector describes the relationship between two words and we can often find analogies by looking for pairs of words with similar displacement vectors, e.g. `v[queen] - v[king] ~ v[woman] - v[man]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec learns continuous word embeddings by assuming the \"distributional hypothesis\". The means words may be characterized by words they are close to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11abd6c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEeCAYAAACZlyICAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhQxVPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11842f490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = pd.Series([0.1, 0.4, 0.01, 0.2, 0.05],\n",
    "             index=[\"pumpkin\", \"shoe\", \"tree\", \"prince\", \"luck\"])\n",
    "s.plot(kind='bar')\n",
    "sb.plt.ylabel(\"$P(w|Cinderella)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec uses a neural network with one hidden layer.\n",
    "\n",
    "<img src=\"http://www.folgertkarsdorp.nl/content/images/2015/01/neural-network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model considers each word along with a given context, e.g., $w_0$ = Cinderella, and $C$ = shoe. Given a context, can we predict $w_0$? This is mutlticlass classification with as many labels as our vocabulary size. We train by minimizing the cross entropy between the network output and the target distribution (as a one-hot vector) via stochastic gradient descent.\n",
    "\n",
    "We have two weights matrices $W$ and $W'$ with dimensions $V \\times N$ and $N \\times V$ where $V$ is our vocabulary size and $N$ is the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'the king loves the queen',\n",
    "    'the queen loves the king',\n",
    "    'the dwarf hates the king',\n",
    "    'the queen hates the dwarf',\n",
    "    'the dwarf poisons the king',\n",
    "    'the dwarf poisons the queen'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vocabulary():\n",
    "    dictionary = defaultdict()\n",
    "    dictionary.default_factory = lambda: len(dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def docs2bow(docs, dictionary):\n",
    "    \"\"\"\n",
    "    transform a list of strings into a list of lists with each unique item converted\n",
    "    into a unique integer (equal to the order of first appearance for a word in the corpus)\n",
    "    \"\"\"\n",
    "    # what is below is slicker way of doing this thing:\n",
    "    # retd = []\n",
    "    # for doc in docs:\n",
    "    #     retd.append([dictionary[word] for word in doc.split()])\n",
    "    # return retd\n",
    "    # ok, but this is cooler:\n",
    "    for doc in docs:\n",
    "        yield [dictionary[word] for word in doc.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "sentences_bow = list(docs2bow(sentences, vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 0, 3],\n",
       " [0, 3, 2, 0, 1],\n",
       " [0, 4, 5, 0, 1],\n",
       " [0, 3, 5, 0, 4],\n",
       " [0, 4, 6, 0, 1],\n",
       " [0, 4, 6, 0, 3]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'dwarf': 4,\n",
       "             'hates': 5,\n",
       "             'king': 1,\n",
       "             'loves': 2,\n",
       "             'poisons': 6,\n",
       "             'queen': 3,\n",
       "             'the': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now construct $W$ and $W'$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V, N = len(vocabulary), 3\n",
    "WI = (np.random.random((V, N)) - 0.5) / N\n",
    "WO = (np.random.random((N, V)) - 0.5) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3)\n",
      "(3, 7)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(WI)\n",
    "print np.shape(WO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14256685,  0.07760353, -0.08811524],\n",
       "       [ 0.02855081,  0.10705906,  0.12814954],\n",
       "       [ 0.01072809,  0.03650268,  0.08153707],\n",
       "       [-0.14193338, -0.02325736, -0.13493665],\n",
       "       [-0.11538327, -0.09355099, -0.09103295],\n",
       "       [-0.11477681, -0.03040523, -0.07367318],\n",
       "       [ 0.09000847, -0.0269599 , -0.15371617]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11035288, -0.09358348, -0.11186635, -0.01527572, -0.14394198,\n",
       "         0.06560251,  0.00589856],\n",
       "       [ 0.05008315, -0.07036849,  0.07293546, -0.09941825, -0.10766639,\n",
       "         0.10530506,  0.04712601],\n",
       "       [ 0.10166214, -0.14258583,  0.05384612, -0.10994551, -0.01022062,\n",
       "         0.03903154, -0.056038  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row $i$ in $W$ corresponds to a word $i$ and each column $j$ corresponds to the $j$th dimension ($j$th hidden neuron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With these matrices we can compute the distance between an input word and the probability an output is a given value. For example, if the input is 'dwarf', what is the probability the output is 'hates'? The dot of the matrices gives us a \"distance\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['dwarf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11538327, -0.09355099, -0.09103295])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WI[vocabulary['dwarf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06560251,  0.10530506,  0.03903154])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WO.T[vocabulary['hates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0209739800237\n"
     ]
    }
   ],
   "source": [
    "print np.dot(WI[vocabulary['dwarf']], WO.T[vocabulary['hates']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king 0.0303610182723\n",
      "dwarf 0.0276112058126\n",
      "queen 0.0210719019858\n",
      "poisons 1.20245642558e-05\n",
      "loves 0.00118255058962\n",
      "the -0.00120705654063\n",
      "hates -0.0209739800237\n"
     ]
    }
   ],
   "source": [
    "for word in vocabulary.keys():\n",
    "    print word, np.dot(WI[vocabulary['dwarf']], WO.T[vocabulary[word]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a softmax function, we can trasnform these outputs into probabilities across our whole vocabulary:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_O|w_I) = y_i = \\frac{exp(W_I \\cdot W_{O}^{'T})}{\\sum_{j=1}^{V} exp(W_I \\cdot W_{j}^{'T})}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.exp(-np.dot(WI[vocabulary['dwarf']], WO.T[vocabulary['hates']])) / \\\n",
    "    sum(np.exp(-np.dot(WI[vocabulary['dwarf']], WO.T[vocabulary[w]])) for w in vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147078088345\n"
     ]
    }
   ],
   "source": [
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the hidden-to-output layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec initially embeds words randomly, so we must learn better positions. We train by minimizing a loss function, $E = - \\log P(w_O | w_I)$. Given the one-hot target distribution, $t$, the error may be computed as $t_j - y_j = e_j$, where $t_j$ is 1 iff $w_j$ is the actual output word.\n",
    "\n",
    "To obtain the gradient on the hidden-to-output weights, we compute $e_j \\cdot h_i$, where $h_i$ is a copy of the vector for the input word (this is true only with the context of a single word). Then we may use stochastic gradient descent with learning rate $\\nu$ to obtain an update equation for the hidden-to-output weights:\n",
    "\n",
    "\\begin{equation}\n",
    "W_{j}^{'T(t)} = W_{j}^{'T(t-1)} - \\nu \\cdot e_j \\cdot h_j \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139511454877 king 1 0.860488545123\n",
      "0.140891857345 dwarf 0 -0.140891857345\n",
      "0.14159770185 queen 0 -0.14159770185\n",
      "0.143549169417 poisons 0 -0.143549169417\n",
      "0.143364523437 loves 0 -0.143364523437\n",
      "0.14424683487 the 0 -0.14424683487\n",
      "0.146838458205 hates 0 -0.146838458205\n"
     ]
    }
   ],
   "source": [
    "target_word = 'king'\n",
    "input_word = 'queen'\n",
    "learning_rate = 1.0\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_word_queen = (\n",
    "        np.exp(-np.dot(WO.T[vocabulary[word]], WI[vocabulary[input_word]])) / \n",
    "            sum(np.exp(-np.dot(WO.T[vocabulary[w]], WI[vocabulary[input_word]])) for w in vocabulary)\n",
    "    )\n",
    "    t = 1 if word == target_word else 0\n",
    "    error = t - p_word_queen\n",
    "    print p_word_queen, word, t, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139511454877 king 1 0.860488545123 [-0.09358348 -0.07036849 -0.14258583]\n",
      "new =  [ 0.02854857 -0.0503558  -0.02647439]\n",
      "0.140226043676 dwarf 0 -0.140226043676 [-0.14394198 -0.10766639 -0.01022062]\n",
      "new =  [-0.16384473 -0.11092768 -0.02914225]\n",
      "0.141036121117 queen 0 -0.141036121117 [-0.01527572 -0.09941825 -0.10994551]\n",
      "new =  [-0.03529345 -0.10269837 -0.12897645]\n",
      "0.143090247182 poisons 0 -0.143090247182 [ 0.00589856  0.04712601 -0.056038  ]\n",
      "new =  [-0.01441072  0.0437981  -0.07534612]\n",
      "0.143019768293 loves 0 -0.143019768293 [-0.11186635  0.07293546  0.05384612]\n",
      "new =  [-0.13216563  0.06960919  0.03454751]\n",
      "0.14401421202 the 0 -0.14401421202 [-0.11035288  0.05008315  0.10166214]\n",
      "new =  [-0.1307933   0.04673376  0.08222934]\n",
      "0.146719678387 hates 0 -0.146719678387 [ 0.06560251  0.10530506  0.03903154]\n",
      "new =  [ 0.04477809  0.10189275  0.01923368]\n",
      "[[-0.1307933   0.04673376  0.08222934]\n",
      " [ 0.02854857 -0.0503558  -0.02647439]\n",
      " [-0.13216563  0.06960919  0.03454751]\n",
      " [-0.03529345 -0.10269837 -0.12897645]\n",
      " [-0.16384473 -0.11092768 -0.02914225]\n",
      " [ 0.04477809  0.10189275  0.01923368]\n",
      " [-0.01441072  0.0437981  -0.07534612]]\n"
     ]
    }
   ],
   "source": [
    "target_word = 'king'\n",
    "input_word = 'queen'\n",
    "learning_rate = 1.0\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_word_queen = (\n",
    "        np.exp(-np.dot(WO.T[vocabulary[word]], WI[vocabulary[input_word]])) / \n",
    "            sum(np.exp(-np.dot(WO.T[vocabulary[w]], WI[vocabulary[input_word]])) for w in vocabulary)\n",
    "    )\n",
    "    t = 1 if word == target_word else 0\n",
    "    error = t - p_word_queen\n",
    "    print p_word_queen, word, t, error, WO.T[vocabulary[word]]\n",
    "    WO.T[vocabulary[word]] = (\n",
    "        WO.T[vocabulary[word]] - learning_rate * error * WI[vocabulary[input_word]]\n",
    "    )\n",
    "    print \"new = \", WO.T[vocabulary[word]]\n",
    "    \n",
    "print WO.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the input-to-hidden layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must backpropagate the prediction errors to the input-to-hidden weights. We first compute $EH$, which is an $N$-dimensional vector representing the sum of the hidden-to-ouput vectors for each word in the vocabulary weighted by their prediction error:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{j=1}^V e_j \\cdot W_{i,j}^{'} = EH_i\n",
    "\\end{equation}\n",
    "\n",
    "Using the learning rate $\\nu$ we update the weights with:\n",
    "\n",
    "\\begin{equation}\n",
    "W_{w_I}^{(t)} = W_{w_I}^{(t-1)} - \\nu \\cdot EH \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WI[vocabulary[input_word]] = WI[vocabulary[input_word]] - learning_rate * WO.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the probability of 'king' given 'queen' has gone up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king 0.139486600404\n",
      "dwarf 0.146483201397\n",
      "queen 0.141514672801\n",
      "poisons 0.14126816146\n",
      "loves 0.145938145581\n",
      "the 0.145891292642\n",
      "hates 0.139417925715\n"
     ]
    }
   ],
   "source": [
    "for word in vocabulary:\n",
    "    p = (np.exp(-np.dot(WO.T[vocabulary[word]],\n",
    "                       WI[vocabulary[input_word]])) /\n",
    "        sum(np.exp(-np.dot(WO.T[vocabulary[w]], \n",
    "                          WI[vocabulary[input_word]]))\n",
    "           for w in vocabulary))\n",
    "    print word, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-word context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model described above is the CBOW architecture of Word2Vec. But, we assumed the context $C$ was only a single input word. This allowed us to simply copy the input vector to the hidden layer. But, if $C$ is multiple words, we take the mean of their input vectors as the hidden layer:\n",
    "\n",
    "\\begin{equation}\n",
    "h = \\frac{1}{C} (W_1 + W_2 + \\cdots + W_C)\n",
    "\\end{equation}\n",
    "\n",
    "The update function remains the same, when we update the input vectors, we need to apply the update to each word in the context:\n",
    "\n",
    "\\begin{equation}\n",
    "W_{W_I}^{(t)} = W_{W_I}^{(t-1)} - \\frac{1}{C} \\cdot \\nu \\cdot EH \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_word = 'king'\n",
    "context = ['queen', 'loves']\n",
    "\n",
    "h = (WI[vocabulary['queen']] + WI[vocabulary['loves']]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13598794,  0.00759668,  0.03526455])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11126467 -0.08822655 -0.11261188 -0.01587416 -0.14415935  0.06388817\n",
      "   0.00490321]\n",
      " [ 0.04782468 -0.05687919  0.07070152 -0.10161356 -0.10982799  0.10296029\n",
      "   0.04487704]\n",
      " [ 0.08729353 -0.05675665  0.03961821 -0.12394062 -0.02403741  0.02418933\n",
      "  -0.07033761]]\n"
     ]
    }
   ],
   "source": [
    "for word in vocabulary:\n",
    "    p = (np.exp(-np.dot(WO.T[vocabulary[word]], h)) / \n",
    "        sum(np.exp(-np.dot(WO.T[vocabulary[w]], h))\n",
    "           for w in vocabulary))\n",
    "    t = 1 if word == target_word else 0\n",
    "    error = t - p\n",
    "    WO.T[vocabulary[word]] = (WO.T[vocabulary[word]] - learning_rate * error * h)\n",
    "    \n",
    "print WO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in context:\n",
    "    WI[vocabulary[word]] = (WI[vocabulary[word]] - (1. / len(context)) * learning_rate * WO.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king 0.144947901187\n",
      "dwarf 0.148342289977\n",
      "queen 0.140526540949\n",
      "poisons 0.139215599995\n",
      "loves 0.146253831606\n",
      "the 0.1457400502\n",
      "hates 0.134973786086\n"
     ]
    }
   ],
   "source": [
    "for word in vocabulary:\n",
    "    p = (np.exp(-np.dot(WO.T[vocabulary[word]],\n",
    "                       WI[vocabulary[input_word]])) /\n",
    "        sum(np.exp(-np.dot(WO.T[vocabulary[w]], \n",
    "                          WI[vocabulary[input_word]]))\n",
    "           for w in vocabulary))\n",
    "    print word, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
